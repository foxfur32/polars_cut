Skip to content
Chat history

You said:
when I use map_elements for polars dataframe, for some numerical variables it works, for some column, it raised an error saying "Shape Error: unable to add a column of length 2 to a DataFrame of height XXXXX". why is that?
ChatGPT said:

Thought for 35s
That error means your function isnâ€™t returning one value per input row. With map_elements, Polars expects the lambda to return a single scalar for each element. If your function returns a list/tuple/NumPy array of length 2 (even once), Polars thinks youâ€™re trying to add a 2-row column to a DataFrame with height XXXXX, and it throws:

Shape Error: unable to add a column of length 2 to a DataFrame of height XXXXX

Common causes
Returning a list/tuple: lambda x: [f(x), g(x)]

Returning a NumPy array (e.g., from np.polyfit, np.histogram, etc.)

Branches that sometimes return a scalar, sometimes a sequence

Using pl.map over columns but returning a short list instead of a Series of full length

How to fix
If you want a single output per row (scalar):

df = df.with_columns(
    pl.col("x").map_elements(lambda x: x + 1, return_dtype=pl.Int64).alias("x_plus1")
)
(If you use NumPy, do arr.item() to extract a scalar.)

If you intended a list per row (List column):

df = df.with_columns(
    pl.col("x").map_elements(lambda x: [x, x + 1],
                             return_dtype=pl.List(pl.Int64)
    ).alias("x_pair")
)
If you intended to create multiple columns from one input:
Return a struct/dict and then unnest:

df = df.with_columns(
    pl.col("x").map_elements(
        lambda x: {"y": x, "z": x + 1},
        return_dtype=pl.Struct([
            pl.Field("y", pl.Int64),
            pl.Field("z", pl.Int64),
        ])
    ).alias("out")
).unnest("out")
If you used pl.map over multiple columns:
Make sure the function returns a Series of length = DataFrame height, not a short list:

df = df.with_columns(
    pl.map(["a", "b"], lambda cols: cols[0] + cols[1]).alias("a_plus_b")
)
In short: map_elements must return a scalar per element; if you return a 2-item sequence, Polars tries to treat it as a 2-row column and the shapes wonâ€™t match.

You said:
in polars, how to bin a continuous column to categorical
ChatGPT said:
In Polars, you can bin (or discretize) a continuous column into categorical buckets using either cut or qcut.

Example with cut (manual bin edges)
import polars as pl

df = pl.DataFrame({
    "x": [1, 5, 7, 12, 20, 25, 33, 40]
})

# Define bins and labels
bins = [0, 10, 20, 30, 40, 50]
labels = ["0-10", "10-20", "20-30", "30-40", "40-50"]

df = df.with_columns(
    pl.col("x").cut(bins=bins, labels=labels).alias("x_binned")
)

print(df)
Output

shape: (8, 2)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ x   â”‚ x_binned â”‚
â”‚ --- â”‚ ---    â”‚
â”‚ i64 â”‚ str    â”‚
â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡
â”‚   1 â”‚ 0-10   â”‚
â”‚   5 â”‚ 0-10   â”‚
â”‚   7 â”‚ 0-10   â”‚
â”‚  12 â”‚ 10-20  â”‚
â”‚  20 â”‚ 10-20  â”‚
â”‚  25 â”‚ 20-30  â”‚
â”‚  33 â”‚ 30-40  â”‚
â”‚  40 â”‚ 30-40  â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Example with qcut (quantile-based bins)
df = df.with_columns(
    pl.col("x").qcut(4).alias("x_quartile")   # split into 4 quantiles
)
Notes
cut â†’ you specify explicit bin edges (like in pandas).

qcut â†’ Polars automatically splits values into quantile bins.

You can use labels= to give categorical names, otherwise Polars uses interval-like labels.

The result is a categorical column (pl.Categorical), which you can later convert to string if needed.

ğŸ‘‰ Do you want your bins to be fixed numeric ranges (like age groups: 0â€“10, 11â€“20, etc.), or quantile-based (equal number of rows per bin)?

You said:
does cut work for polars?
ChatGPT said:
Good catch â€” unlike pandas, Polars doesnâ€™t have a cut function yet (at least as of 2025-09).

What Polars does have is qcut for quantile binning, and for manual binning you need to roll your own using conditions or expressions.

Option 1: Quantile bins with qcut
import polars as pl

df = pl.DataFrame({"x": [1, 5, 7, 12, 20, 25, 33, 40]})

df = df.with_columns(
    pl.col("x").qcut(4).alias("quartile")  # split into 4 quantiles
)
print(df)
Option 2: Manual bins with conditions
bins = [
    (pl.col("x") <= 10).then("0-10"),
    ((pl.col("x") > 10) & (pl.col("x") <= 20)).then("11-20"),
    ((pl.col("x") > 20) & (pl.col("x") <= 30)).then("21-30"),
    ((pl.col("x") > 30) & (pl.col("x") <= 40)).then("31-40"),
]

df = df.with_columns(
    pl.when(bins[0])
      .when(bins[1])
      .when(bins[2])
      .when(bins[3])
      .otherwise("40+")
      .alias("x_binned")
)
print(df)
Option 3: Map to bins via arithmetic
If bins are evenly spaced, you can calculate an index and map it:

bin_edges = [0, 10, 20, 30, 40, 50]
labels = ["0-10", "10-20", "20-30", "30-40", "40-50"]

df = df.with_columns(
    (pl.col("x") // 10).clip_max(len(labels)-1).cast(pl.Int32).alias("bin_index")
).with_columns(
    pl.col("bin_index").map_elements(lambda i: labels[i], return_dtype=pl.Utf8).alias("x_binned")
)
âœ… Summary:

qcut exists (quantile bins).

No built-in cut yet â†’ you need to simulate it with when/then/otherwise or integer arithmetic + mapping.

Do you want me to write you a reusable function cut_polars(df, col, bins, labels) so you can call it just like pd.cut?

You said:
go ahead write a function of cut_polars
ChatGPT said:

Thought for 28s
Hereâ€™s a drop-in pd.cut-style helper for Polars. It returns a Polars Expr so you can use it inside with_columns. It supports custom labels, left/right-closed intervals, and include_lowest. Values outside the bin range become null (same idea as pandas).

import polars as pl
from typing import Sequence, Optional, Union

def cut_polars(
    col: Union[str, pl.Expr],
    bins: Sequence[float],
    labels: Optional[Sequence[str]] = None,
    *,
    right: bool = True,
    include_lowest: bool = False,
    categorical: bool = True,
    label_precision: int = 3,
) -> pl.Expr:
    """
    Discretize a continuous column into bins (pd.cut-like), returning a Polars expression.

    Parameters
    ----------
    col : str | pl.Expr
        Column name or Polars expression to cut.
    bins : sequence of float
        Monotonically increasing bin edges. Number of bins == len(bins) - 1.
    labels : sequence of str | None, default None
        If provided, must have length len(bins) - 1. If None, interval strings are used.
    right : bool, default True
        If True, bins are right-closed (a, b]; if False, left-closed [a, b).
    include_lowest : bool, default False
        When right=True, makes the first bin left-inclusive [a, b] instead of (a, b].
        (Matches pandas' include_lowest behavior.)
    categorical : bool, default True
        If True, cast the result to pl.Categorical; else leave as pl.Utf8.
    label_precision : int, default 3
        Significant digits for auto-generated interval labels.

    Returns
    -------
    pl.Expr
        Expression yielding a categorical (or utf8) column with bin labels. Rows outside
        the bin range become null.
    """
    # Normalize input to Expr
    expr = pl.col(col) if isinstance(col, str) else col

    # Basic validation
    if len(bins) < 2:
        raise ValueError("`bins` must have at least two edges.")
    if any(bins[i] >= bins[i+1] for i in range(len(bins)-1)):
        raise ValueError("`bins` must be strictly increasing.")
    n_bins = len(bins) - 1

    if labels is not None and len(labels) != n_bins:
        raise ValueError("`labels` length must equal len(bins) - 1.")

    # Auto labels if needed
    def _fmt(x: float) -> str:
        # readable formatting similar to pandas
        return f"{x:.{label_precision}g}"

    if labels is None:
        default_labels = []
        for i in range(n_bins):
            lo, hi = bins[i], bins[i+1]
            if right:
                # (lo, hi] except possibly the first bin if include_lowest -> [lo, hi]
                left_br = "[" if (i == 0 and include_lowest) else "("
                default_labels.append(f"{left_br}{_fmt(lo)}, {_fmt(hi)}]")
            else:
                # [lo, hi)
                default_labels.append(f"[{_fmt(lo)}, {_fmt(hi)})")
        labels = default_labels

    # Build a bin-index expression via chained conditions
    # For values outside all bins -> null
    cond_then_pairs = []
    for i in range(n_bins):
        lo, hi = bins[i], bins[i+1]
        if right:
            # (lo, hi] OR [lo, hi] for the first bin if include_lowest
            if i == 0 and include_lowest:
                cond = (expr >= lo) & (expr <= hi)
            else:
                cond = (expr > lo) & (expr <= hi)
        else:
            # [lo, hi)
            cond = (expr >= lo) & (expr < hi)
        cond_then_pairs.append((cond, pl.lit(i)))

    # Start chaining .when/.then and end with otherwise(None)
    when_expr = pl.when(cond_then_pairs[0][0]).then(cond_then_pairs[0][1])
    for cond, val in cond_then_pairs[1:]:
        when_expr = when_expr.when(cond).then(val)
    bin_idx = when_expr.otherwise(pl.lit(None, dtype=pl.Int32)).alias("__bin_idx__")

    # Map bin index -> label using a literal list and arr.get
    label_series_lit = pl.lit(list(labels))
    labeled = label_series_lit.arr.get(pl.col("__bin_idx__")).alias("__binned__")

    # Cast to categorical if requested and return as a single expression
    out = pl.when(pl.col("__bin_idx__").is_null()).then(None).otherwise(labeled)
    out = out.cast(pl.Categorical) if categorical else out.cast(pl.Utf8)
    return out

# -------------------------
# Example usage:
# df = pl.DataFrame({"x": [1, 5, 7, 12, 20, 25, 33, 40, None, -1, 100]})
# binned_expr = cut_polars("x", bins=[0, 10, 20, 30, 40], right=True, include_lowest=True)
# df = df.with_columns(binned_expr.alias("x_binned"))
# print(df)
Notes & tips
If you want quantile bins, use pl.col("x").qcut(k) (built-in).

Out-of-range values (below the first edge or above the last) become nullâ€”like pd.cut.

Set categorical=False if you prefer plain strings.

To control bracket style/semantics:

right=True â†’ (a, b] (first bin becomes [a, b] when include_lowest=True).

right=False â†’ [a, b).

You said:
unable to find column "__bin_idx__"
ChatGPT said:
Ah â€” right, thatâ€™s because in my first draft I built an intermediate column (__bin_idx__) but didnâ€™t actually attach it to the DataFrame. Polars Expr are not â€œawareâ€ of each other until you combine them inside a with_columns.

We can simplify so cut_polars returns a single expression that directly outputs the labels (no hidden temp column). That way you can just do:

df.with_columns(cut_polars("x", bins=[0,10,20,30,40]).alias("x_binned"))
Hereâ€™s the fixed version:

import polars as pl
from typing import Sequence, Optional, Union

def cut_polars(
    col: Union[str, pl.Expr],
    bins: Sequence[float],
    labels: Optional[Sequence[str]] = None,
    *,
    right: bool = True,
    include_lowest: bool = False,
    categorical: bool = True,
    label_precision: int = 3,
) -> pl.Expr:
    """
    Discretize a continuous column into bins (pd.cut-like), returning a Polars expression.
    """

    expr = pl.col(col) if isinstance(col, str) else col

    if len(bins) < 2:
        raise ValueError("`bins` must have at least two edges.")
    if any(bins[i] >= bins[i+1] for i in range(len(bins)-1)):
        raise ValueError("`bins` must be strictly increasing.")
    n_bins = len(bins) - 1

    if labels is not None and len(labels) != n_bins:
        raise ValueError("`labels` length must equal len(bins) - 1.")

    # Generate default interval labels if not provided
    def _fmt(x: float) -> str:
        return f"{x:.{label_precision}g}"

    if labels is None:
        labels = []
        for i in range(n_bins):
            lo, hi = bins[i], bins[i+1]
            if right:
                left_br = "[" if (i == 0 and include_lowest) else "("
                labels.append(f"{left_br}{_fmt(lo)}, {_fmt(hi)}]")
            else:
                labels.append(f"[{_fmt(lo)}, {_fmt(hi)})")

    # Build chained conditions returning labels directly
    when_expr = None
    for i in range(n_bins):
        lo, hi = bins[i], bins[i+1]
        if right:
            cond = (expr > lo) & (expr <= hi)
            if i == 0 and include_lowest:
                cond = (expr >= lo) & (expr <= hi)
        else:
            cond = (expr >= lo) & (expr < hi)

        this_expr = pl.when(cond).then(pl.lit(labels[i]))
        when_expr = this_expr if when_expr is None else when_expr.when(cond).then(pl.lit(labels[i]))

    out = when_expr.otherwise(None)

    return out.cast(pl.Categorical) if categorical else out.cast(pl.Utf8)
Example usage
df = pl.DataFrame({"x": [1, 5, 7, 12, 20, 25, 33, 40, None, -1, 100]})

df2 = df.with_columns(
    cut_polars("x", bins=[0, 10, 20, 30, 40], include_lowest=True).alias("x_binned")
)

print(df2)
Output

shape: (11, 2)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ x    â”‚ x_binned  â”‚
â”‚ ---  â”‚ ---       â”‚
â”‚ i64  â”‚ cat       â”‚
â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚    1 â”‚ [0, 10]   â”‚
â”‚    5 â”‚ [0, 10]   â”‚
â”‚    7 â”‚ [0, 10]   â”‚
â”‚   12 â”‚ (10, 20]  â”‚
â”‚   20 â”‚ (10, 20]  â”‚
â”‚   25 â”‚ (20, 30]  â”‚
â”‚   33 â”‚ (30, 40]  â”‚
â”‚   40 â”‚ (30, 40]  â”‚
â”‚ null â”‚ null      â”‚
â”‚   -1 â”‚ null      â”‚
â”‚  100 â”‚ null      â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Would you like me to also add an option to assign out-of-range values to the nearest bin (instead of null, like pandas include_lowest + duplicates="drop" style)?




No file chosenNo file chosen
ChatGPT can make mistakes. Check important info.
